{
    "model":"meta-llama/Llama-2-13b-chat-hf",
    "disable_log_requests": "true",
    "tensor_parallel_size": 2,
    "worker_use_ray": "false"
}
